Many practical problems in statistical inference involve "latent" variables, by
which I will mean high-dimensional, unobserved nuisance parameters or missing
data which must be accounted for when performing inference on some
lower-dimensional quantity of primary interest.  Common examples include random
effects models (the random effects are the latent variables) and mixture models
(where the component indicators are the latent variables).  I will introduce and
discuss variational inference (VI) methods for latent variable problems, drawing
connections both with Bayesian approaches (Markov Chain Monte Carlo and the
maximum a-posteriori estimator) and frequentist approaches (maximum likelihood
estimators and the EM algorithm).  I will focus particularly on providing
intuition on when VI is or is not helpful, how it can go wrong, and briefly
survey some modern approaches to alleviating its shortcomings.
