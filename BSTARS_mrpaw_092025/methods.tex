
\begin{frame}{The basic problem}

%\adjincludegraphics[width=0.9\textwidth,trim={0 {.5\height} 0 0 }, clip]{static_figures/survey_and_voting.jpg}

We have a survey population, for whom we observe:
%
\begin{itemize}
 \item Covariates $\x$ (e.g.~race, gender, zip code, age, education level)
 \item Responses $\y$ (e.g.~A binary response to ``do you support policy such--and--such'')
\end{itemize}
%

We want the average response in a target population,
in which we observe only covariates.



\splitpage{
    \centering
    \only<1>{
    \includegraphics[width=0.5\textwidth]{static_figures/survey_man.jpg}
    }
    \only<2->{
    \includegraphics[width=0.5\textwidth]{static_figures/survey_crazy_man.jpg}
    }
}{
    \centering
    \includegraphics[width=0.5\textwidth]{static_figures/voting_man.jpg}
}

\splitpage{
    \centering
    Observe $(\x_s, y_s)$ for $s = 1, \ldots, \nsur$\\
}{
    \centering
    Observe $\x_p$ for $p = 1, \ldots, \ntar$\\
}

\onslide<2->{
\textbf{The problem is that the populations are very different.}
}

\onslide<3->{
    Our survey results may be biased.

    How can we use the covariates
    to say something about the target responses?
}
%
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Two approaches}

We want $\mu := \meantar \y_p$, but don't observe $\y_p$ in the target population.

\begin{itemize}
    \item Assume $p(y | x)$ is the same in both populations,
    \item But the distribution of $x$ may be different in the survey and target.
\end{itemize}
%

\splitpage{
    \centering
    \textbf{Calibration weighting}
}{
    \centering
    \textbf{Bayesian hierarchical modeling (MrP)}
}

\splitpage{
    \centering
    Choose ``calibration weights'' $w_s$\\
    (e.g.~raking weights)
}{
    \centering
    Choose a model $\p(\y | x, \theta)$ and prior $\p(\theta)$\\
    (e.g.~Hierarchical logitstic regression)
}

\splitpage{
    \centering
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}

\splitpage{
    \centering
    Dependence on $\y_s$ is obvious\\
    ($\w_s$ typically chosen using only $\x$)
}{
    \centering
    Dependence on $\y_s$ very complicated\\
    (Typically via MCMC draws from $\p(\theta \vert \textrm{Survey data})$)
}

\splitpage{
    \centering
    Weights give interpretable diagnostics:
    %
    \begin{itemize}
        \item Frequentist variability
        \item Partial pooling
        \item Regressor balance
    \end{itemize}
    %
}{
    \centering
    \textbf{Black box}
}

We open the MrP black box, and provide versions of all these diagnostics,
for nonlinear hierarchical models fit with MCMC.

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}

What do we want out of calibration weights?

$$
\textrm{Target average} =
\meantar \y_p \approx \meansur \w_s \y_s
= \textrm{Weighted survey average}
$$

We can't check this, because we don't observe $\y_p$.  But we can check
whether

$$
% \textrm{Target average regeressor} =
    \meantar \x_p = \meansur \w_s \x_s
% =    \textrm{Weighted survey average regressor}
$$

Such weights satisfy ``covariate balance'' for $\x$.

You can check covariate balance for any calibration weighting estimator.

Even more, covariate balance is the criterion for a popular class of calibration
weight estimators:

\begin{block}{Raking calibration weights}
% Select calibration weights to satisfy
$$
\begin{aligned}
    \textrm{ Take }
    \w_1, \ldots, \w_{\Nsur} :={}& \argmin \sumsur (\w_s - \w_s^{\mathrm{ref}})^2 \\
    \textrm{Subject to }
    \meantar f(\x_p) ={}& \meansur \w_s f(\x_s)
    \textrm{ for some function }f(\cdot).
\end{aligned}
$$
\end{block}



\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}

Why would you want covariate balance?  Some commonly stated reasons:

%
\begin{itemize}
\item To reduce the variance of inverse propensity weights (IPW)
\item To check the accuracy of IPW
\item To exactly balance ``important regressors''
\end{itemize}
%
Common to these motivations is the following concen:

% \begin{block}{Why covariate balance?}
    We want to balance $f(\x)$ because we think
    $\expect{}{\y \vert \x}$ might plausibly vary $\propto f(\x)$.
    % \\[1em]

    Covariate balance ensures that such variation is captured
    by our calibration estimator.
% \end{block}


\begin{block}{General covariate balance check}
    Pick a small $\delta$, and define a \emph{new response variable} $\ytil$ such that
    $$
    \expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x).
    $$
    We know the change this perturbation produces in the target distribution:
    $$
    \mu(\ytil) - \mu(\y) = \delta \meantar f(\x_p)
    $$
    Covariate balance for an estimator $\muhat$ checks whether
    $\muhat(\ytil) - \muhat(\y) = \mu(\ytil) - \mu(\y)$.
\end{block}


\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{MrPaw}

How to form a notion of covariate balance for estimators that are not weighted averages?

\splitpage{
    \centering
    \textbf{Calibration weights}\\
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    \textbf{MrP}\\
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}


\vspace{1em}
\hrulefill\\
\textbf{Step one: Define weights.}

Noting that $w_s = \frac{d}{d \y_s} \muhat_{\cal}$, we can define

$$
\wmrp_s := \frac{d}{d\y_s} \muhat_{\mrp}. %= \meantar \frac{d}{d\y_s} \yhat_p.
$$

It happens that the needed derivatives are given
by simple a posterior covariances involving only the inverse
link function $m(\x; \theta)$ and
log likelihood \citep{giordano:2018:covariances}:

$$
\frac{d \yhat_p}{d\y_s}  =
    \cov{\p(\theta \vert \textrm{Survey data})}{
        m(\x_p; \theta),
        \frac{\partial}{\partial \y} \log p(\y \vert \theta, \x_s)}
$$

These can be computed using standard MCMC software \citep{brms}.

No other weight definition will do --- in some cases,
MrP is exactly a calibration estimator (e.g. linear regression with flat priors),
and we want the definitions to coincide in that case.

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}


How to form a notion of covariate balance for estimators that are not weighted averages?

\splitpage{
    \centering
    \textbf{Calibration weights}\\
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    \textbf{MrP}\\
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}

\vspace{1em}
\hrulefill\\
\textbf{Step two: Specify a Taylor series.}

\def\new{\mathrm{new}}
Suppose we wanted to re--compute MrP with new
survey responses $\y_s^{\new}$.

$$
\muhat_{\mrp}(\y_1^\new, \ldots, \y_{\nsur}^\new) =
\sumsur \w_s^\mrp (\y_s^\new  - \y_s) + \mathrm{Residual}
$$

In general, MrP is truly nonlinear. The residual is only small when $\y_s^\new \approx \y_s$!


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}


How to form a notion of covariate balance for estimators that are not weighted averages?

\splitpage{
    \centering
    \textbf{Calibration weights}\\
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    \textbf{MrP}\\
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}

\vspace{1em}
\hrulefill\\
\textbf{Step three: Define a data perturbation that captures regression balance.}



\end{frame}



