
\begin{frame}{The basic problem}

%\adjincludegraphics[width=0.9\textwidth,trim={0 {.5\height} 0 0 }, clip]{static_figures/survey_and_voting.jpg}

We have a survey population, for whom we observe:
%
\begin{itemize}
 \item Covariates $\x$ (e.g.~race, gender, zip code, age, education level)
 \item Responses $\y$ (e.g.~A binary response to ``do you support policy such--and--such'')
\end{itemize}
%

We want the average response in a target population,
in which we observe only covariates.



\splitpage{
    \centering
    \only<1>{
    \includegraphics[width=0.5\textwidth]{static_figures/survey_man.jpg}
    }
    \only<2->{
    \includegraphics[width=0.5\textwidth]{static_figures/survey_crazy_man.jpg}
    }
}{
    \centering
    \includegraphics[width=0.5\textwidth]{static_figures/voting_man.jpg}
}

\splitpage{
    \centering
    Observe $(\x_s, y_s)$ for $s = 1, \ldots, \nsur$\\
}{
    \centering
    Observe $\x_p$ for $p = 1, \ldots, \ntar$\\
}

\onslide<2->{
\textbf{The problem is that the populations are very different.}
}

\onslide<3->{
    Our survey results may be biased.

    How can we use the covariates
    to say something about the target responses?
}
%
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Two approaches}

We want $\mu := \meantar \y_p$, but don't observe $\y_p$ in the target population.

\begin{itemize}
    \item Assume $p(y | x)$ is the same in both populations,
    \item But the distribution of $x$ may be different in the survey and target.
\end{itemize}
%

\splitpage{
    \centering
    \textbf{Calibration weighting}
}{
    \centering
    \textbf{Bayesian hierarchical modeling (MrP)}
}

\splitpage{
    \centering
    Choose ``calibration weights'' $w_s$\\
    (e.g.~raking weights)
}{
    \centering
    Choose a model $\p(\y | x, \theta)$ and prior $\p(\theta)$\\
    (e.g.~Hierarchical logitstic regression)
}

\splitpage{
    \centering
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}

\splitpage{
    \centering
    Dependence on $\y_s$ is obvious\\
    ($\w_s$ typically chosen using only $\x$)
}{
    \centering
    Dependence on $\y_s$ very complicated\\
    (Typically via MCMC draws from $\p(\theta \vert \textrm{Survey data})$)
}

\splitpage{
    \centering
    Weights give interpretable diagnostics:
    %
    \begin{itemize}
        \item Frequentist variability
        \item Partial pooling
        \item Regressor balance
    \end{itemize}
    %
}{
    \centering
    \textbf{Black box}
}

We open the MrP black box, and provide versions of all these diagnostics,
for nonlinear hierarchical models fit with MCMC.

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}

What do we want out of calibration weights?

$$
\textrm{Target average} =
\meantar \y_p \approx \meansur \w_s \y_s
= \textrm{Weighted survey average}
$$

We can't check this, because we don't observe $\y_p$.  But we can check
whether

$$
% \textrm{Target average regeressor} =
    \meantar \x_p = \meansur \w_s \x_s
% =    \textrm{Weighted survey average regressor}
$$

Such weights satisfy ``covariate balance'' for $\x$.

You can check covariate balance for any calibration weighting estimator.

Even more, covariate balance is the criterion for a popular class of calibration
weight estimators:

\begin{block}{Raking calibration weights}
% Select calibration weights to satisfy
``Raking'' selects weights that
%
\begin{itemize}
    \item Are as ``close as possible'' to some reference weights
    \item Under the constraint that they balance some selected regressors.
\end{itemize}
%
% $$
% \begin{aligned}
%     \textrm{ Take }
%     \w_1, \ldots, \w_{\Nsur} :={}& \argmin \sumsur (\w_s - \w_s^{\mathrm{ref}})^2 \\
%     \textrm{Subject to }
%     \meantar f(\x_p) ={}& \meansur \w_s f(\x_s)
%     \textrm{ for some function }f(\cdot).
% \end{aligned}
% $$
\end{block}



\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Why covariate balance?}

% Why would you want covariate balance?  Some commonly stated reasons:
% %
% \begin{itemize}
% \item To reduce the variance of inverse propensity weights (IPW)
% \item To check the accuracy of IPW
% \item To exactly balance ``important regressors''
% \end{itemize}
%
% Common to these motivations is the following concen:

\begin{alertblock}{Why covariate balance?}
We want to balance $f(\x)$ because we think
$\expect{}{\y \vert \x}$ might plausibly vary $\propto f(\x)$,
and want to check whether our estimator can capture this variability.
\end{alertblock}


This motivates the following \textbf{generalized covariate balance check}:

\begin{block}{General covariate balance check (informal)}
    Define a \emph{new response variable} $\ytil$ such that
    $$
    \expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x).
    $$
    We know the change this is supposed to induce in the target population.\\[1em]

    Covariate balance checks whether our estimators produce the same change.
    %
\end{block}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}


\begin{block}{General covariate balance check (formal)}
    Pick a small $\delta$, and define a \emph{new response variable} $\ytil$ such that
    $$
    \expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x).
    $$
    We know the expected change this perturbation produces in the target distribution:
    $$
    \begin{aligned}
            \expect{}{\mu(\ytil) - \mu(\y) | \x} =
            \meantar \left(\expect{}{\ytil | \x_p} - \expect{}{\y | \x_p}\right) =
            \delta \meantar f(\x_p)
    \end{aligned}
    $$
    Covariate balance checks whether an estimator $\muhat(\cdot)$ produces
    the same change:
    $$
    \begin{aligned}
    \muhat(\ytil) - \muhat(\y)
        \overset{\textrm{check}}{=}
        \delta \meantar f(\x_p).
    \end{aligned}
    $$
\end{block}

When $\muhat(\y)$ is a calibration estimator, this is the same as covariate balance
in expectation:
$$
\begin{aligned}
    \expect{}{\muhat(\ytil) - \muhat(\y) | \x} =
    % \meansur \w_s \left(\expect{}{\ytil | \x_p} - \expect{}{\y | \x_p}\right) =
    \delta \meansur \w_s f(\x_p) \overset{\textrm{check}}{=}
        \delta \meantar f(\x_p).
\end{aligned}
$$
%
But now all we need to do is compare $\muhat(\ytil) - \muhat(\y)$ for
``nearby'' $\ytil$ and $\y$.



\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{MrPaw}

We need to approximate $\muhat_{\mrp}(\ytil) - \muhat_{\mrp}(\y)$.

\vspace{1em}
\hrulefill\\
\textbf{Step one: Define weights.}

Noting that $w_s = \frac{d}{d \y_s} \muhat_{\cal}$, we can define

$$
\wmrp_s := \frac{d}{d\y_s} \muhat_{\mrp}. %= \meantar \frac{d}{d\y_s} \yhat_p.
$$

It happens that the needed derivatives are given
by simple a posterior covariances involving only the inverse
link function $m(\x; \theta)$ and
log likelihood \citep{giordano:2018:covariances}:

$$
\frac{d \yhat_p}{d\y_s}  =
    \cov{\p(\theta \vert \textrm{Survey data})}{
        m(\x_p; \theta),
        \frac{\partial}{\partial \y} \log p(\y \vert \theta, \x_s)}
$$

These can be computed using standard MCMC software \citep{brms}.

No other weight definition will do --- in some cases,
MrP is exactly a calibration estimator (e.g. linear regression with flat priors),
and we want the definitions to coincide in that case.

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}


How to form a notion of covariate balance for estimators that are not weighted averages?

\splitpage{
    \centering
    \textbf{Calibration weights}\\
    $\muhat_{\cal} = \meansur w_s y_s$
}{
    \centering
    \textbf{MrP}\\
    Take $\yhat_p = \expect{\p(\theta \vert \textrm{Survey data})}{\y | \x_p}$ and\\
    $\muhat_{\mrp} = \meantar \yhat_p$
}

\vspace{1em}
\hrulefill\\
\textbf{Step two: Specify a Taylor series.}

\def\new{\mathrm{new}}
Suppose we wanted to re--compute MrP with new
survey responses $\y_s^{\new}$.

$$
\muhat_{\mrp}(\y_1^\new, \ldots, \y_{\nsur}^\new) =
\sumsur \w_s^\mrp (\y_s^\new  - \y_s) + \mathrm{Residual}
$$

In general, MrP is truly nonlinear. The residual is only small when $\y_s^\new \approx \y_s$!


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}


\textbf{Step three: Define a data perturbation that captures regression balance.}

Recall that our $\y$ is binary.  How can we produce a $\ytil$ such that
$\expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x)$?
%
\begin{itemize}
    \item Use an estimate of $\expect{}{\y \vert \x}$ to draw new binary data, or
    \item Allow $\ytil$ to take values other than $\{0,1\}$ and set
        $\ytil = \y + \delta \f(\x)$.
\end{itemize}
%
Focus on the second (we have examples of the first).

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}

\begin{block}{Theorem}
    %
    \begin{itemize}
        \item Let $\ytil = \y + \delta \f(\x)$,
        \item $\muhat_{\mrp}$ be a hierachical logistic regression posterior expectation, and
        % \item $\mathcal{F}$ a class of functions such that
        %     $\sup_{\f \in \mathcal{F}} \expect{}{\norm{\x \f(\x)}_2^2} < \infty$
        \item $\mathcal{F}$ be a class of uniformly bounded functions on $\x$.
    \end{itemize}
    %
    Then, with probability approaching one, as $N \rightarrow \infty$,
    $$
    \begin{aligned}
        \sup_{\f \in \mathcal{F}} \left(
            \muhat_\mrp(\ytil) -
            \left(\muhat_\mrp(\y) + \sumsur \w_s^{\mrp} \delta \f(\x_s) \right)
            \right)
        = O(\delta^2)
        \quad\textrm{as }\delta \rightarrow 0
    \end{aligned}
    $$
\end{block}

The supremum over $\mathcal{F}$ is the primary technical contribution!
It means we are justified in searching over regressors
to find imbalance.

Draws on our prior work on uniform and finite--sample error bounds for Bernstein--von Mises
theorem--like results \citep{giordano:2024:bayesij,kasprzak:2025:laplace}.

In practice, compute
$$
\textrm{Imbalance}(\f) := \sumsur \w_s^{\mrp} \f(\x_s)  - \meantar \f(\x_p)
$$
for any $\f(\cdot)$ you think might capture variability in $\y$.

\end{frame}





