
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Generalized covariate balance for MrP}

\textbf{Step one:} Construct
$\ytil$ such that $\expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x)$.
\pause

\textbf{Problem:} Our $\y$ is binary!  (We're motivated by hierarchical linear regression.)

\pause
Two possibilities:
%
\begin{itemize}
    \item Allow $\ytil$ to take values other than $\{0,1\}$ and set
        $\ytil = \y + \delta \f(\x)$, or
    \item Use an estimate of $\expect{}{\y \vert \x}$ to draw new binary $\ytil$.
\end{itemize}
%
Our approach:
%
\begin{itemize}
    \item Use $\ytil = \y + \delta \f(\x)$ to identify problematic ``imbalanced'' $\f(\x)$
    \item Sanity check by generating binary $\ytil$ using $\f(\x)$ (which is fast and easy)
\end{itemize}


\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Generalized covariate balance for MrP}

\textbf{Step one:} Construct
$\ytil$ such that $\expect{}{\ytil \vert \x} = \expect{}{\y \vert \x} + \delta f(\x)$.\\
\pause
\textbf{Step two:} Evaluate \surcol{$\muhat_\mrp(\ytil) - \muhat(\y)$}.
\pause

\textbf{Problem:} \surcol{$\muhat_\mrp(\cdot)$} is computed with MCMC.
%
\begin{itemize}
\item Each MCMC run typically takes hours, and
\item Output is noisy, and \surcol{$\muhat_\mrp(\ytil) - \muhat(\y)$} may be small.
\end{itemize}
%

\pause
\begin{block}{MrP Local Equivalent Weights (MrPlew)}
Form the approximation
\surcol{
$$
\muhat_{\mrp}(\ytil) =
    \sumsur \w_i^\mrp (\ytil_i  - \y_i) + \mathrm{Residual}
\quad\textrm{where}\quad
    \wmrp_i := \frac{d}{d\y_i} \muhat_{\mrp}(\y). %= \meantar \frac{d}{d\y_s} \yhat_p.
$$
}
\end{block}

\only<5>{
The weights are given by weighted averages of posterior covariances  \parencite{giordano:2018:covariances}.
\\[1em]
They can be easily computed with standard software\footnote{We use \texttt{brms} \parencite{brms}.}
\textbf{without re--running MCMC}.\\
}


\only<6>{
    We state conditions under which, as $\delta \rightarrow 0$, and $N \rightarrow \infty$, \\
    the residual is of lower order than the MrPlew term, \textit{uniformly in $\f(\cdot)$}.\\[1em]

    Based on prior work on uniform and finite--sample error bounds
    for Bernstein--von Mises theorem--like results \parencite{giordano:2024:bayesij}.\\[1em]

    (See also \textcite{kasprzak:2025:laplace}!)

}


\only<7>{
If MrP were linear (e.g.~if you use OLS instead of hierarchical
logistic regression), then
%
\begin{itemize}
\item The residual is zero,
\item $\muhat_{\mrp}(\y) = \sumsur \w_i^\mrp \y_i$, and so
\item $\muhat_{\mrp}(\ytil)$ is a calibration weighting
estimator, and $\wmrp_i$ are its weights.  (Cite Gelman)
\end{itemize}
%
In general, MrP is truly nonlinear. The residual is only small when $\ytil \approx \y$
(i.e., when $\delta \ll 1$).
}




\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Covariate balance}

\begin{block}{Theorem}
    %
    \begin{itemize}
        \item Let $\ytil = \y + \delta \f(\x)$,
        \item $\muhat_{\mrp}$ be a hierachical logistic regression posterior expectation, and
        % \item $\mathcal{F}$ a class of functions such that
        %     $\sup_{\f \in \mathcal{F}} \expect{}{\norm{\x \f(\x)}_2^2} < \infty$
        \item $\mathcal{F}$ be a Donsker class of uniformly bounded functions on $\x$.
    \end{itemize}
    %
    Then, with probability approaching one, as $N \rightarrow \infty$,
    $$
    \begin{aligned}
        \sup_{\f \in \mathcal{F}} \left(
            \muhat_\mrp(\ytil) -
            \left(\muhat_\mrp(\y) + \sumsur \w_s^{\mrp} \delta \f(\x_s) \right)
            \right)
        = O(\delta^2)
        \quad\textrm{as }\delta \rightarrow 0
    \end{aligned}
    $$
\end{block}

The supremum over $\mathcal{F}$ is the primary technical contribution!
It means we are justified in searching over regressors
to find imbalance.

Draws on our prior work on uniform and finite--sample error bounds for Bernstein--von Mises
theorem--like results \parencite{giordano:2024:bayesij,kasprzak:2025:laplace}.

% In practice, compute
% $$
% \textrm{Imbalance}(\f) := \sumsur \w_s^{\mrp} \f(\x_s)  - \meantar \f(\x_p)
% $$
% for any $\f(\cdot)$ you think might capture variability in $\y$.

\end{frame}




