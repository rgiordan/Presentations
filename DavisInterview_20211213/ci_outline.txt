
https://ubc-dsci.github.io/introduction-to-datascience/



Recall our running example from previous classes.  We are interested in the
average price of Airbnbs in our city because we're interested in whether they
might be out-competing the traditional hotel industry.

Now, if we actually knew the price of every Airbnb, we could just calculate  the
average price directly!  We'll call this number \mu.  It's the quantity we
wish we knew but don't.

The problem is that, typically, Airbnb doesn't release that information to us.
So we have talked about how to _estimate_ the true average over all rentals
using a _random sample_.  To get a random sample, we select forty listings at
random, looked up their prices, and averaged them together.  We'll call this
estimate \hat\mu.  It is common in statistics to put a hat symbol over an
estimator of a particular quantity.  Typically, unless we get veeerrry lucky,
\hat\mu \ne \mu, because our random sample is different from the full sample.

Now, because this is a class, we actually have a full dataset from Airbnb,
so we can compute both the true value \mu, and simulate drawing a
random sample.  In particular, we can run the following R code:

...

Note that each time we draw a new sample, we get a new value for \hat\mu. There
is a spread of possible values, centered around the truth.  Now, we were only
able to plot this spread because this is a statistics class and we are happen to
know not only the truth, but the whole dataset. So we can draw many random
samples to see how they behave.  But in real life, you only get to see one of
these \hat\mu values, and you don't know where in this distribution you've
landed.  Worse, if you know only \hat\mu, you don't even know how big the spread
is! Your estimate might be arbitrarily far away from the truth as far as you
know.  What use is \hat\mu to you if you don't know how wrong it might be?

This is an introductory class, and I assume some of you have not seen this
before.  So I hope some of you are wondering now: is it hopeless?  If you cannot
see all these other potential draws --- and in the real world you can't --- how
can you know the spread?  How can you know how far away your estimate might be?
How can you measure not only your estimate, but the uncertainty of your
estimate?

Well, having answers to this question is what separates statistics from other
disciplines. As my old boss at Google used to say, any computer scientist can
compute an estimator, but it takes a statistician to compute the uncertainty.
It's worth acknowledging that, in full generality, measuring uncertainty is
hard.  But there are some situations --- for example, sample averages --- which
have been studied for a long time, and for which we have pretty good techniques.
