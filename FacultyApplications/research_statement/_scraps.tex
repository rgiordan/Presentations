
% The key idea is that, although there are a very large number of subsets
% containing 0.1\% of the data points, none of them are very different from the
% original dataset, and so we expect the linear approximation to work well.
% I confirm this intuition with finite-sample accuracy bounds in terms of
% intuitive and verifiable assumptions. I provide an \texttt{R} package
% \citep{zaminfluence} to compute the approximation quickly and automatically
% using automatic differentiation \citep{baydin:2015:automatic, autograd}.  And,
% with my co-authors, I show that the approximation is capable of detecting
% meaningful non-robustness in several published econometrics analyses.

% In recent work, I identify problematic subsets of the data using {\em
% sensitivity analysis}---that is, by forming a linear approximation to the
% dependence of statistical estimators on their datasets.

In fact, my research shows that many standard, computationally demanding data
analysis tasks are also amenable to fast, automatic approximation using
sensitivity analysis. For example:
%
\begin{itemize}
    %
\item Cross validation (CV) requires repeatedly leaving out subsets of the
observed data and re-evaluating a statistical estimator. By forming a Taylor
series approximation on the dependence of the estimator on the left-out set, I
provide fast approximations to CV with finite-sample accuracy guarantees
\citep{giordano:2019:ij}.
%
\item
% Prior specification encodes key assumptions in Bayesian statistics.  But
% Bayesian inference can be sensitive to prior specification, and evaluating the
% sensitivity of Bayesian posterior expectations to prior specification by
% re-fitting is typically computationally prohibitive due both to the large space
% of possible priors (often infinite dimensional), as well as the high
% computational cost of evaluating even a single posterior approximation.

By
forming a Taylor series approximation to the dependence of the posterior mean on
the prior, I can explore the consequences of alternative prior functional forms
at a small fraction of the cost of exact re-fitting
\citep{giordano:2020:rstansensitivity, giordano:2021:bnpsensitivity}.
%
\item

% When analyzing randomly sampled data using possibly misspecified Bayesian
% posteriors, frequentist variability in excess of posterior variability is
% symptomatic of \emph{data non-robustness}. For example, one might worry that a
% new random sample of poll respondents in the presidential forecast model of
% \citet{economist:2020:election} would lead to a different prediction.  This
% frequentist variability can be evaluated by the bootstrap, but at the
% considerable cost of re-running Markov Chain Monte Carlo (MCMC) hundreds of
% times.

By approximating the dependence of the posterior on the data with
sensitivity analysis, I compute accurate estimates of the frequentist variance
using only a single MCMC chain---orders of magnitude faster than the bootstrap
\citep{giordano:2020:stanconbayesij}.
%
\item Mean field variational Bayes (MFVB) is a popular posterior approximation
method for Bayesian problems which are too large to be tractable by Markov Chain
Monte Carlo \citep{blei:2017:variational, regier:2019:cataloging}.  However,
MFVB approximations provide notoriously poor estimates of posterior uncertainty
\citep{turner:2011:two}.  In \citet{giordano:2018:covariances}, I show that
accurate posterior covariances can be recovered from MFVB approximations with
sensitivity analysis by exploiting a duality between Bayesian covariances and
sensitivity.
%
\end{itemize}

For the remainder of this statement, I will elaborate each of these themes,
emphasizing the ways in which I update classical results with intuitive,
relevant theory and easy-to-use computational tools.

\newpage
