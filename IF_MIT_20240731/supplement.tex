

    



\begin{frame}[t]{Example: A negative binomial model}


Consider $\p(\xvec \vert \gamma) = \prod_{n=1}^N \textrm{NegativeBinomial}(\x_n \vert \gamma)$. Here, $\theta = \gamma$ is a scalar.  

\pause
As $N \rightarrow \infty$, $\p(\gamma \vert \xvec)$ concentrates at rate $1 / \sqrt{N}$ (Bernstein--von Mises).

$\Rightarrow 
N \left( \expect{\p(\gamma \vert \xvec, \w_n)}{\gamma} -
\expect{\p(\gamma \vert \xvec)}{\gamma} \right) = \blue{\infl_n} (\w_n - 1) + \red{O_p(N^{-1})}.
$


\pause
\vspace{1.5em}
\LowDimAccuracyGraph{}

\pause
\question{\textbf{Problem:} Most computationally hard Bayesian problems don't concentrate.}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Experiments}

Example: \textbf{Poisson model with random effects (REs)
$\lambda$ and fixed effect $\gamma$.}

\HighDimAccuracyGraph{}

\end{frame}


\begin{frame}{A contradiction?}
    %
    \vspace{-1em}
    \begin{align*}
    %
    &\text{\textbf{Negative binomial observations.}}
    &
    &\text{\textbf{Poisson observations with random effects.}}
    \\
    &\text{\textbf{Asymptotically linear in $\w$.}}
    &
    &\text{\textbf{Asymptotically non-linear in $\w$.}}
    %
    \onslide<3->{
    \\
    &\log \p(\xvec \vert \gamma, \w^{m}) =
        \sumn \w^{m}_n \log \p(\x_n \vert \gamma)
    &
    &\log \p(\xvec \vert \gamma, \lambda, \w^{c}) =
        \sumn \w^{c}_n \log \p(\x_n \vert \lambda, \gamma)
    }
    %
    \end{align*}
    
    \onslide<2->{
    \begin{center}
        % \large
    With a constant regressor, Gamma REs, and one RE per observation,\\
    these are the same model, with the same $\p(\gamma \vert \xvec)$.
    
    % \spskip
    \textbf{Is $\expect{\p(\gamma \vert \xvec, \w)}{\gamma}$
    linear in the \only<1-2>{data weights}\only<3->{\red{data weights}}
    or not?}
    }
    
    \onslide<3->{
    \pause
    \spskip
    \textbf{\red{Trick question!}}  We weight a log likelihood
    contribution, not a datapoint.
    
    % % \spskip
    \textbf{The two weightings are not equivalent in general.}
    }
    
    \end{center}
    %
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Experimental results}
    Our results were actually computed on \textbf{identical datasets}
    with $G = N$ and $g_n=n$.

    \begin{center}
    \begin{minipage}{0.34\textwidth}
        Uses $\log \p(\x_n \vert \gamma)$:\\
        $\infl_n = \expect{\p(\gamma \vert \xvec)}{\gammabar \ellbar_n(\gamma)}$

        \onslide<2->{
        \spskip
        Not computable from\\
        $\gamma, \lambda \sim \p(\gamma, \lambda \vert \xvec)$\\
        in general.
        }
    \end{minipage}
    \begin{minipage}{0.65\textwidth}
        \LowDimAccuracyGraph{}
        % \HighDimAccuracyGraph{}
    \end{minipage}
    %

    \begin{minipage}{0.34\textwidth}
        Uses $\log \p(\x_n \vert \gamma, \lambda)$:\\
        $\infl_n = \expect{\p(\gamma,\lambda \vert \xvec)}{\gammabar \ellbar_n(\gamma, \lambda)}$

        \onslide<2->{
        \spskip
        Computable from\\
        $\gamma, \lambda \sim \p(\gamma, \lambda \vert \xvec)$.
        }

        \onslide<3->{
        \spskip
        May still be useful when $\p(\lambda \vert \xvec)$
        is {\em somewhat} concentrated.
        }

    \end{minipage}
    \begin{minipage}{0.65\textwidth}
        %\LowDimAccuracyGraph{}
        \HighDimAccuracyGraph{}
    \end{minipage}
    %
\end{center}
    %
\end{frame}

