\documentclass[twoside,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}

\usepackage[style=authoryear,natbib=true]{biblatex}
\addbibresource{references.bib}
\addbibresource{possible_references.bib}

%\usepackage[authoryear]{natbib}
\input{_math_macros}

\numberwithin{equation}{section}

\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{mathrsfs}

\newcommand{\papersection}[2][]{\subsection*{\citefield{#2}{title} \parencite{#2} #1}}


\begin{document}

\title{Notes on \citet{bates:2021:distributionpredictionsets}}

\author{Ryan Giordano}


\maketitle

\section{Setup and problem statement}


This paper takes as given a black-box algorithm $\f(\cdot)$ that operates on
pairs $\z_n := (\x_n, \y_n)$, producing a prediction $\f(\xnew) := \ynew$,
which we hope satisfies $\yhatnew \approx \ynew$ (though we assume nothing of the
form).  The algorithm $\f(\cdot)$ is typically constructed from a training
set, which we will ignore.

We have some calibration set, $\calset := \{ \zcal_1, \ldots, \zcal_\n\}$,
which we would like to use to form \textit{interval-valued} predictions
for $\ynew$ from $\ynew$.  That is, we will use the observations in $\calset$
to form a (random) set-valued function, $\cfun(\xnew)$.  (We could
write $\cfun(\xnew | \calset)$, to emphasize
the dependence on the calibration set but that would get tedious.)

I'll use $\s(\cdot)$ for the mapping and $\s$ for sets.

How to choose the mapping $\cfun(\cdot)$ to have desirable properties?
We define a family of candidate sets, and a loss function describing
what a ``good'' set looks like.  Specifically, let's take
%
\begin{itemize}
%
    \item A nested one-dimensional family of set functions,
    $\cfun_{\lambda}(\cdot)$ such that bigger $\lambda$ results in bigger sets:
    $$\lambda_1 < \lambda_2 \Rightarrow \cfun_{\lambda_1}(\x) \subset
    \cfun_{\lambda_2}(\x) \textrm{ for all }\x.$$
    %
    \item A loss function $\loss(\y, \s)$ which increases as sets get smaller:
    $$\s \subset \s \Rightarrow \loss(\y, \s) \ge \loss(\y,\s').$$
%
\end{itemize}
%
\paragraph{Tension:} We want small sets (small $\lambda$), but also want small
$\loss$ (big $\lambda$).  This paper is all about how to choose $\lambda$ to
balance these desiderata with statistical guarantees.

\paragraph{How to choose sets? }The paper points out that for models which
return an estimate of the relative probabilities of $\y$, one can
correspondingly impute the probability of $\loss(\y, \s + \{\y\})$, and doing
so greedily design a nested family of sets which is optimal if your model is
correct.


\paragraph{Problem: } How to use the calibration
set $\calset$ to choose $\lambdahat$ so that the loss
$\loss(\ynew, \cfun_{\lambdahat}(\xnew)$ is ``probably'' small,
where ``probably'' accounts for randomness in both $\calset$
and in $(\xnew, \ynew)$?


\section{Running example}

The paper really shines in its creation of meaningful loss functions
for complex settings.  But I think this short exposition will be 
better served by a much more familiar example which connects
more closely to more standard conformal inference.

Suppose $\ynew \in \bbr$ (so it's like a regression problem), and
we want to flag $\ynew$ that we think are too big.
So what we want is a one-sided confidence interval for $\ynew$:
%
\begin{align*}
%
\cfun_\lambda(\xnew) ={}& \{ \y: \y \le \yhat + \lambda \}\\
\loss(\y, \s) ={}& \ind{\lambda < \y}.
%
\end{align*}
%
So we incur a loss of one if we fail to cover.  This satisfies
the above definitions. $\square$

Note that classical conformal inference gives a solution
to this problem using the non-conformity score $\y - \yhat$,
setting $\lambda$ to be an appropriate quantile,
controlling 
%
\begin{align*}
%
\p{\calset,\znew}{\loss(\ynew, \cfun_{\lambdahat}(\xnew) \ge \alpha}
%
\end{align*}
%
This paper will do something a little different, though we'll
try to connect the two at the end.


\section{This paper's solution}

\subsection{Define probably small} 
First, the paper defines ``probably small'' as
%
\begin{align*}
%
\p{\calset}{
    \expect{\znew}{\loss(\ynew, \cfun_{\lambdahat}(\xnew)} \le \alpha
} =:
\p{\calset}{\risk(\lambdahat) \le \alpha}
\ge 1 - \delta
%
\end{align*}
%
The expectation will be called the ``risk,'' and we'll use it enough
to give it a name:
%
\begin{align*}
%
\risk(\cfun_\lambda) = \risk(\lambda) =
    \expect{\znew}{\loss(\ynew, \cfun_{\lambda}(\xnew)}.
%
\end{align*}
%
Note that this is different than standard conformal prediction (see above),
though the two are related.  \citet{vovk:2012:conditionalconformal} calls this
``training conditional'' validity because the inner expectation has the
calibration set fixed.  It is also a guarantee similar to ``tolerance regions''
\citep{krishnamoorthy:2009:statisticaltoleranceregions}, which we will discuss
if we have time.

\paragraph{Example. }
In our running example,
%
\begin{align*}
%
\risk(\lambda) =
    \expect{\znew}{\ind{\ynew - \yhat > \lambda}} = 
    \p{\znew}{\ynew - \yhat > \lambda}.
%
\end{align*}
%
That is, $\risk(\lambda)$ is just one minus the distribution function of the
non-conformity score, evaluated at $\lambda$.  So we want to choose $\lambdahat$
so that it is larger than the true $1-\alpha$ quantile, with probability (in the
calibration set) at least $1-\delta$.  This amounts to constructing a good
estimate of the distribution function --- which we can do using the empirical
distribution function on the calibration set.  $\square$

\subsection{Control the risk using the calibration set} 

How to control $\risk(\cdot)$ using $\calset$? 
If you knew the risk function, you would simply take
%
\begin{align*}
    %
    \lambdastar := \inf \{ \lambda: \risk(\lambda) \le \alpha \}
    \textrm{ and }\delta = 0.
    %
\end{align*}
%
But we don't, so we have to estimate $\risk(\cdot)$ using $\calset$. Note that
we're going to both estimate the function $\lambda \mapsto \risk(\lambda)$, and
then search over our estimate to pick a $\lambda$.  You might think that would
require a uniform bound on the accuracy of our approximation, but it won't, due
to a clever expolitation of monotonicity of the loss.


The authors assume that you can form a one-sided lower confidence region for
$\risk(\lambda)$, for any $\lambda$ (pointwise).  That is, that you can find an
upper confidence bound (UCB) $\rupper(\lambda)$ such that
%
\begin{align*}
%
\p{\calset}{\risk(\lambda) \le \rupper(\lambda)} \ge 1 - \delta.
%
\end{align*}
%
This UCB is all you need!  There are lots of ways to construct it, using
concentration inequalities, or even asymptotics (we will talk later).  But once
you have it, you can take
%
\begin{align*}
%
\lambdahat := \inf\{\lambda: \rupper(\lambda') < \alpha
\textrm{ for all }\lambda' > \lambda \}.
%
\end{align*}
%
Here's their proof that this works (in the case that $\risk(\lambda)$
is continuous):
%
\begin{itemize}
    \item Suppose we picked $\lambdahat$ ``too small:'' $\lambdahat <
    \lambdastar$, and $\risk(\lambdahat) > \risk(\lambdastar) = \alpha$.  We
    failed to achieve our bound --- the risk at $\lambdahat$ is too high.
    %
    \item But we chose $\lambdahat$ so that $\lambdahat < \lambdastar
    \Rightarrow \rupper(\lambdastar) < \alpha = \risk(\lambdastar)$. In other
    words, the risk $\risk(\lambdastar)$ is outside its confidence interval
    $(-\infty, \rupper(\lambdastar))$.
    %
    \item By construction $\rupper(\cdot)$, this can happen with
    probability at most $1 - \delta$.  Therefore we fail to control
    risk with probability no more than $1-\delta$.
    %
\end{itemize}


\subsection{Choose an upper confidence bound} 

We now need only choose an UCB.  Note that we can compute
%
\begin{align*}
%
\riskhat(\lambda) := \meann \loss(\y_n, \cfun_\lambda(\x_n)).
%
\end{align*}
%
For any $\lambda$, $\riskhat(\lambda)$ is an unbiased estimate of
$\risk(\lambda)$.  Different concentration results of $\riskhat(\lambda)$ to its
mean $\risk(\lambda)$ can give a family of UCB.

The simplest example is Hoeffding in the case that $\loss(\cdot) \in [0,1]$:
%
\begin{align*}
%
\p{\calset}{\riskhat(\lambda) - \risk(\lambda) < -t} &\le
\exp\left(-2\n t^2 \right) = \delta \Leftrightarrow \\
\p{\calset}{\risk(\lambda) > \riskhat(\lambda) + t} &\le
\exp\left(-2\n t^2 \right) = \delta \Leftrightarrow \\
\rupper(\lambda) &:= \riskhat(\lambda) + \sqrt{\ln \delta / (-2 \n)}.
%
\end{align*}
%
This is loose, but easy to understand.  For bounded losses they actually
recommend the Waudby-Smith-Ramdas bound, which is based on a maximal inequality
for martingales and is better able to take into account different
variances for different $\lambda$.

For unbounded losses, you need to assume something.  They consider
a Pinelis-Utev inequality, but also consider asymptotic normal bounds.

Again, the fact that $\risk(\lambda)$ is monotonic eliminates the need
to use bounds of the form $\sup_{\lambda} (\riskhat(\lambda) - \risk(\lambda))$.
Simple pointwise bounds are enough.


\paragraph{Example. } In our example, we need to control
%
\begin{align*}
%
%\meann \ind{\y_n - \yhat_n > \lambda} - \p{\znew}{\ynew_n - \yhat(\xnew_n) > \lambda}.
\meann \ind{\y_n - \yhat_n > \lambda} - \risk(\lambda),
%
\end{align*}
%
where we used the fact that the risk is the expected loss.  Note
that this quantity is $1/N$ times a binomial random variable
with probability $\risk(\lambda)$.  

If we knew $\risk(\lambda) = \rho$, then we can use the binomial
distribution to find $t(\risk(\lambda))$ such that 
%
\begin{align*}
%
\p{\calset}{\meann \ind{\y_n - \yhat_n > \lambda} - \rho
    \ge t(\rho)} \ge 1 - \delta.
%
\end{align*}
%
That is, we can form an exact, finite-sample test of the hypothesis
$\risk(\lambda) = \rho$.  We can then invert the test to find
a UCB:
%
\begin{align*}
%
\rupper(\lambda) := \sup \{\rho: 
    \textrm{We do not reject }\rho\textrm{ for the observed } \calset\}.
%
\end{align*}
%
$\square$

The paper generalizes the preceding idea with a number of different
concentration inequalities.






\section{Experiments}

Their experiments exhibit a lot of clever loss functions, and show that
their procedure results in reasonable (not too wide) intervals whose
risk centers, roughly, on the target.  Going through the experiments
is probably too much for a short oral talk; check out the paper.



\section{A classical version}

Let's assume that each loss, $\lambda \mapsto \loss(\y_n, \cfun_\lambda(\x_n))$
is also monotonic (non-increasing).

An alternative to the present work would be to use the smallest $\lambda$ needed
to achieve a given loss on a \textit{particular example} as a non-conformity
score:
%
\begin{align*}
%
\ell_n := \ell(\z_n) := \inf \{ \lambda: \loss(\y_n, \cfun_\lambda(\x_n)) \le \alpha \}.
%
\end{align*}

By monotonicity, if $\lambda \ge \ell(\z_n)$, then $\loss(\y_n,
\cfun_\lambda(\x_n)) \le \alpha$.  So we want to choose $\lambdahat$ to
guarantee that $\ell(\znew) \ge \lambdahat$ with high probability. To acheive
this, we can take as $\lambdahat$ the appropriate quantile of the non-conformity
scores: $\lambdahat := \ell_{(\lfloor \delta (\n + 1) \rfloor)}$. This would
guarantee
%
\begin{align*}
%
\p{\calset,\znew}{\loss(\ynew, \cfun_{\lambdahat} (\ynew) \le \alpha}
\ge
\p{\calset,\znew}{\ell(\znew) \ge \lambdahat}
\ge 1 - \delta.
%
\end{align*}
%
This is more in the spirit of \citet{gupta:2022:nestedconformal} (which the
authors cite as the source of the idea of nested sets).

\paragraph{Example. } In our example, the loss function is binary,
so we can only control the probability that it's non-zero
--- we cannot target a loss equal to any $\alpha \in (0, 1)$.
But the formalism works; for any $\alpha > 0$,
%
\begin{align*}
%
\ell(\z_n) =
\inf \{ \lambda: \loss(\y_n, \cfun_\lambda(\x_n)) \le \alpha \} &=
\inf \{ \lambda: \ind{\y_n - \yhat \ge \lambda} \le \alpha \} = \y_n - \yhat.
\end{align*}
%
So $\lambdahat$ is the $\lfloor \delta (\n + 1) \rfloor$-th quantile of the
non-conformity scores, and this procedure returns the standard conformal
one-sided interval. $\square$

The nature of the bound is different, though as pointed out by
\citet{vovk:2012:conditionalconformal}, one implies the other for bounded
losses, and with different constants.  But the computational requirements are
different as well.
%
\begin{itemize}
%
\item The present paper requires computation of $\rupper(\lambda)$ and then
(roughly speaking) inversion of the map $\lambda \mapsto \rupper(\lambda)$.
%
\item The above approach requires inversion of the map $\lambda \mapsto
\loss(\y_n, \cfun_\lambda(\x_n))$, but then only a quantile computation
to get $\lambdahat$.
%
\end{itemize}
%
I expect this proposal to require more computational effort, especially
for complicated loss functions.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\printbibliography{}




\end{document}
