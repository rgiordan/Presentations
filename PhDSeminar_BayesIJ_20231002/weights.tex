\begin{frame}{Data re-weighting.}


\onslide<2->{
Augment the problem with {\em data weights} $\w_1, \ldots, \w_N$.
We can write $\expect{\p(\theta \vert \xvec, \w)}{f(\theta)}$.
}
\onslide<2->{
%
\begin{align*}
%
\ell_n(\theta) :={}& \log \p(\x_n \vert \theta)
&
\log \p(\xvec \vert \theta, \w) ={}&
    \sumn \w_n \ell_n(\theta)
%
\end{align*}
}

\begin{minipage}{0.49\textwidth}
    \onslide<2-> {
    Original weights: \par
    \includegraphics[width=0.78\textwidth]{static_figures/orig_weights}
    }
    \onslide<3-> {
    \par Leave-one-out weights: \par
    \includegraphics[width=0.78\textwidth]{static_figures/weights_loo}
    }
    \onslide<4-> {
    \par Bootstrap weights: \par
    \includegraphics[width=0.78\textwidth]{static_figures/boot_weights}
    }
\end{minipage}
%\onslide<1->{
\begin{minipage}{0.49\textwidth}
    % https://www.overleaf.com/learn/latex/TikZ_package
    % https://latexdraw.com/how-to-annotate-an-image-in-latex/
    % https://tex.stackexchange.com/questions/9559/drawing-on-an-image-with-tikz
    \begin{tikzpicture}
        \onslide<5-> {
        \node[anchor=south west,inner sep=0] (image) at (0,0) {
            %\includegraphics[width=0.98\textwidth]{static_figures/weight_slope}
            \includegraphics[width=0.98\textwidth]{static_figures/e_beta_w}
        };
        }
        \onslide<7->{
        \begin{scope}[x={(image.south east)},y={(image.north west)}]
            \draw[gray, thick, <-] (0.2,0.23) -- ++(0.1,0.25)
                    node[above,black,fill=white]
                    {\small $\expect{p(\theta \vert \x)}{f(\theta)}$};
        \end{scope}
        }
        \onslide<6->{
        \begin{scope}[x={(image.south east)},y={(image.north west)}]
            \draw[gray, thick, <-] (0.8,0.8) -- ++(-0.1,0.1)
                    node[left,black,fill=white]
                    {\small $\expect{p(\theta \vert \x, \w_n)}{f(\theta)}$};
        \end{scope}
        }
        \onslide<8->{
        \begin{scope}[x={(image.south east)},y={(image.north west)}]
            \draw[blue, thick, -] (0.18,0.18) -- ++(1.2 * 0.6, 1.2 * 0.48);
        \end{scope}
        }
        \onslide<9->{
        \begin{scope}[x={(image.south east)},y={(image.north west)}]
            \draw[gray, thick, <-] (0.4,0.35) -- ++(0.2,-0.08)
                    node[right,black,fill=white]
                    {\small Slope $ = \blue{\infl_n}$};
        \end{scope}
        }
        \onslide<10->{
        \begin{scope}[x={(image.south east)},y={(image.north west)}]
            \draw[gray, thick, <-] (0.8,0.65) -- ++(0.02,-0.2)
                    node[below,black,fill=white]
                    {\small Error $ = \red{\err(\w)}$};
            \draw[red, to-to] (0.8,0.76) -- ++(0,-0.07);
        \end{scope}
        }
    \end{tikzpicture}
%}
\end{minipage}

\onslide<11->{
The re-scaled slope $N \infl_n$ is known as the
``influence function'' at data point $\x_n$.
%
\vspace{-0.5em}
\begin{align*}
\expect{p(\theta \vert \xvec, \w)}{f(\theta)} -
    \expect{p(\theta \vert \xvec)}{f(\theta)} ={}&
    \sumn \blue{\infl_n} (\w_n - 1) +
    \red{\err(\w)}
    % \textrm{Higher order derivatives}
%
\end{align*}
}
%
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\def\expansion{
%
\begin{align*}
%
\expect{p(\theta \vert \xvec, \w)}{f(\theta)} -
    \expect{p(\theta \vert \xvec)}{f(\theta)} ={}&
    \sumn \blue{\infl_n} (\w_n - 1) + \red{\err(\w)}
%
\end{align*}
%
}

\input{how_to_use}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t]{Experessions for the slope and error}

\question{How to compute the slopes \blue{$\infl_n$}?
How large is the error \red{$\err(\w)$}?}

For simplicity, for the remainder of the presentation, we will
consider a single weight.
%
\begin{align*}
%
\expect{p(\theta \vert \xvec, \w_n)}{f(\theta)} -
    \expect{p(\theta \vert \xvec)}{f(\theta)} ={}&
    \blue{\infl_n} (\w_n - 1) + \red{\err(\w_n)}
%
\end{align*}
%
\pause
%
An overbar means centered with respect to $\p(\theta \vert \xvec)$
(e.g., $\thetabar := f(\theta) - \expect{\p(\theta \vert \xvec)}{f(\theta)}$).

\pause
% Re-order $\expect{\p(\theta \vert \xvec, \w_n)}{\cdot}$ and
% $\partial / \partial \w_n$
% with the dominated convergence theorem (DCT):
By exchanging integration and differentiation:

\begin{align*}
%
\blue{\infl_n} ={}&
    \fracat{\partial \expect{\p(\theta \vert \xvec, \w_n)}{f(\theta)}}
       {\partial \w_n}{\w_n =1}
% =     \cov{\p(\theta \vert \xvec)}{\theta, \ell_n(\theta)}
= \blue{
\expect{\p(\theta \vert \xvec)}{ \thetabar \ellbar_n(\theta)}
}
& \blue{\textrm{\textbf{Can estimate with MCMC!}}}
\end{align*}
%

\pause
By the mean value theorem, for some $\wtil_n \in [0,\w_n]$:
%
\begin{align*}
\red{\err(\w_n)} ={}&
\frac{1}{2}
    \fracat{\partial^2
        \expect{\p(\theta \vert \xvec, \w_n)}{f(\theta)}}
    {\partial \w_n^2}{\w_n=\wtil_n} (\w_n - 1)^2 =
\frac{1}{2}
\red{\expect{\p(\theta \vert \xvec, \wtil_n)}{
    \thetabar
    \ellbar_n(\theta)
    \ellbar_n(\theta)}} (\w_n - 1)^2
%
\end{align*}

\pause
The approximation is good if
$
\blue{
\expect{\p(\theta \vert \xvec)}{ \thetabar \ellbar_n(\theta)}
} \gg
\red{\expect{\p(\theta \vert \xvec, \wtil_n)}{
    \thetabar
    \ellbar_n(\theta)
    \ellbar_n(\theta)}}
$.
%
\end{frame}
