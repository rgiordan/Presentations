\documentclass[8pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}


\usetheme{metropolis}           % Use metropolis theme
\usepackage{amsmath}
\usepackage{mathrsfs}

\def\p#1{\mathbb{P}\left(#1\right)}
\def\b#1{\mathbb{B}\left(#1\right)}
\def\ind#1{1\left(#1\right)}
\def\cover{\mathscr{C}}

\title{Fiducial Inference and Subjective Probability}
\author{Ryan Giordano}
\date{Feb 18th, 2022}
\institute{Massachusetts Institute of Technology}

\begin{document}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Are confidence intervals inference?}

Suppose we have a scalar parameter $\theta$, a random variable $X$ with unknown
distribution $\p{\cdot}$, and an interval-valued function $x \mapsto C(x)$ such
that, no matter the distribution of $X$, we know that
%
\begin{align*}
%
\p{\cover = 1} = 0.9
\quad\textrm{ where}\quad
\cover := \ind{\theta \in C(X)}
\quad\textrm{(}\cover\textrm{ is for ``cover'')}\quad
%
\end{align*}
%
The interval $C(X)$ is a {\em valid confidence interval} for $\theta$. This
means that if we act as if $\theta \in C(X)$, we will be wrong at most $10\%$ of
the time.

\pause

\hrulefill

When is it reasonable to interpret $\cover$ {\em inferentially}, saying
that, when we observe $X=x$, that we subjectively believe that $\theta \in C(x)$
with $90\%$ certainty?

\pause
Not always!
Recall, for example, how we can construct silly confidence
intervals. Augment the data with a draw $Z \sim \mathrm{Unif}(0, 1)$, and let
%
\begin{align*}
%
C(X) =
\begin{cases}
    (-\infty, \infty) & \textrm{ when } Z \le 0.9 \\
    [1337, 1337] & \textrm{ otherwise }
\end{cases}.
%
\end{align*}
%
Obviously, no matter what the generating process, $\p{\cover = 1} = 0.9$,
but it is absurd to assert that we are $90\%$ confident that
$\theta = 1337$ because we observed $Z = 0.95$.

\pause

How can we characterize generally and precisely what went wrong?
%
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{A pathological confidence interval}

Write beliefs as $\b{\cdot}$, to contrast with aleatoric
probabiliites $\p{}$. So we ask when
%
\begin{align*}
%
\p{\cover = 1} = 0.9 \quad \Rightarrow \quad
\b{\cover = 1 | X = x} = 0.9
%
\end{align*}

\pause

\hrulefill

Note that Bayesians define priors and completely specified
data generating processes and insist that $\b{} = \p{}$.

Certainly that suffices.  But is it necessary?

\pause

It is often difficult to plausibly specify
everything needed for Bayes.  In such cases it can be hard to
assert that $\b{} = \p{}$.

\pause

We may also want to trade off mathematical or computational effort to achieve
$\b{} \approx \p{}$.  Bayes gives no real guidance for doing so.

\pause

I argue that potential answers may be found in {\em fiducial inference}.

Here, I will follow Ian Hacking's book, {\em The Logic of
Statisical Inference}.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Fiducial inference for confidence intervals}

Fiducial inference for confidence intervals requires three key assumptions.
The first two are uncontroversial, the third is where things go wrong.

\pause

\textbf{Assumption 1: The logic of support.}  Formally, any coherent belief
function $\b{}$ obeys Kolmogorov's axioms in the natural ways. Examples:
\begin{itemize}
    \item If proposition $A$ and $B$ are mutually incompatible, then $\b{A | B} = 0$.
    \item If $B$ provides no information about $A$, then $\b{A | B} = \b{A}$.
    \item If $B \Rightarrow A$, then $\b{A | B} = 1$.  And so on.
\end{itemize}

The logic of support is needed to even write and manipulate $\b{\cdot}$.

\pause

\textbf{Assumption 2: The frequency principle.}  If $\p{X}$ is known, then our
subjective beliefs correspond with aleatoric probabilities.  That is,
$\b{X = x} = \p{X = x}$.

\pause

The third is where things can go wrong for confidence intervals.

\textbf{Assumption 3: Irrelevance.} The precise value of the data $X=x$ is not
subjectively informative about whether $\theta \in C(x)$.  That is,
%
\begin{align*}
%
\b{\theta \in C(x) | X = x} = \b{\theta \in C(x)}.
%
\end{align*}
%
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Fiducial inference for confidence intervals}

\textbf{Assumption 1: The logic of support.}

\textbf{Assumption 2: The frequency principle.}

\textbf{Assumption 3: Irrelevance.}

Confidence intervals are valid inference when
%
\begin{align*}
\p{\cover = 1} = 0.9 \quad \Rightarrow \quad
\b{\cover = 1 | X = x} = 0.9.
\end{align*}
%
The above three assumptions are sufficient.

\pause

Proof:
%
\begin{align*}
%
\b{\cover = 1 | X = x} &= \b{\cover = 1}
    & \textrm{Irrelevance}\\
&= \p{\cover = 1}
    & \textrm{The frequency principle}\\
&= \p{\theta \in C(X)} = 0.9.
& \textrm{Construction of }C(\cdot)
%
\end{align*}
%
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{The pathological example is caught}

Clearly enough, the irrelevance assumption is where things can go wrong.
Let's look at our pathological example.

\begin{align*}
%
C(x) =
\begin{cases}
    (-\infty, \infty) & \textrm{ when } z \le 0.9 \\
    [1337, 1337] & \textrm{ otherwise }
\end{cases}.
%
\end{align*}
%

\textbf{Irrelevance:} The precise value of the data $X=x$ is not  subjectively
informative about whether $\theta \in C(x)$.  That is,
%
\begin{align*}
%
\b{\theta \in C(x) | X = x} = \b{\theta \in C(x)}.
%
\end{align*}
%


Our pathological example fails the principle of irrelevance, since
knowing $z \ge 0.9$ is very informative about whether $\theta \in C(x)$.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{How to use this?}

The {\em invalidity} of a CI can be demonstrated by an ability
to predict $1(\theta \in C(x))$ from $x$.

\pause

Given a candidate confidence interval, constructed using any method, this
renders the validity of inference {\em quantitatively falisifiable}, e.g.
through simulation and ML.

\pause

It also admits {\em degrees of valid inference}, e.g. in the sense that
$1(\theta \in C(x))$ may be only slightly
predicted by $x$.

\pause

Computation of $C(x)$ and predictability of $1(\theta \in C(x))$
can in principle be explicitly traded off against one another.

\pause

When you think about how, in practice, to evaluate predictability of
$1(\theta \in C(x))$, you are forced to grapple explicitly with priors,
power, and misspecification, but in {\em simulation}, not necessarily
{\em modeling}.

\pause

\textbf{I think this is very exciting.}

\end{frame}


\end{document}
